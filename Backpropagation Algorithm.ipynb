{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aim:** To build an Artificial Neural Network by implementing the Backpropagation algorithm and test the same using appropriate data sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theory:** Artificial Neural Networks are a branch of Artificial Intelligence and Machine Learning which involve solving Machine Learning prediction problems.\n",
    "They are inspired form Human Neural Network and replicate the functionality of human nervous system involving neurons , dendrites etc.\n",
    "\n",
    "ANN consists of several nodes which behave as neurons. The nodes are connected by links (wires) for communication with one another. Nodes take input data to perform small operations on trained data and results of these operations are passed to other nodes (neurons). The output at the node is called its node value\n",
    "\n",
    "Neural networks have a remarkable ability to retrieve meaningful data from imprecise data, that is used in detecting trends and extract patterns which are difficult to understand either by computer or humans. A trained NN can be made an \"expert\" in information that has been given to analyse and can be used for provide projections.\n",
    "\n",
    "An ANN includes a huge number of processors working parallely, which are arranged in layers. The first layer receives the raw data as input, similar to optic nerves of human eye visual processing. Every successive layer receives the raw input data as output from the previous layer, similar to neurons of optic nerve receiving signals from those close to it. The final layer generates output. Below image shows several layers.\n",
    "They are multiple types of Neural Networks like Freeforward , Convolutional , Recurrent , Modular.\n",
    "Artificial Neural Networks are used in multiple fields like pattern recognition , facial recognition , handwriting identification , speech to text transfer , weather prediction , stock market prediction , path/fare prediction.\n",
    "\n",
    "Backpropagation is an algorithm commonly used to train neural networks. When the neural network is initialized, weights are set for its individual elements, called neurons. Inputs are loaded, they are passed through the network of neurons, and the network provides an output for each one, given the initial weights. Backpropagation helps to adjust the weights of the neurons so that the result comes closer and closer to the known true result.\n",
    "It involves following steps\n",
    "1. Visualizing the input data\n",
    "2. Deciding the shapes of Weight and bias matrix\n",
    "3. Initializing matrix, function to be used\n",
    "4. Implementing the forward propagation method\n",
    "5. Implementing the cost calculation\n",
    "6. Backpropagation and optimizing\n",
    "7. prediction and visualizing the output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Used is **Iris Dataset**<br>\n",
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np    \n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('datasets_19_420_Iris.csv')\n",
    "iris = iris.sample(frac=1).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.5, 2.5, 4. , 1.3],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.9, 3. , 5.1, 1.8],\n",
       "       [5.4, 3.9, 1.7, 0.4]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = iris[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
    "X = np.array(X)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "Y = iris.Species\n",
    "Y = one_hot_encoder.fit_transform(np.array(Y).reshape(-1, 1))\n",
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeuralNetwork(X_train, Y_train, X_val=None, Y_val=None, epochs=10, nodes=[], lr=0.15):\n",
    "    hidden_layers = len(nodes) - 1\n",
    "    weights = InitializeWeights(nodes)\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        weights = Train(X_train, Y_train, lr, weights)\n",
    "\n",
    "        if(epoch % 20 == 0):\n",
    "            print(\"Epoch {}\".format(epoch))\n",
    "            print(\"Training Accuracy:{}\".format(Accuracy(X_train, Y_train, weights)))\n",
    "            if X_val.any():\n",
    "                print(\"Validation Accuracy:{}\".format(Accuracy(X_val, Y_val, weights)))\n",
    "            \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitializeWeights(nodes):\n",
    "    \"\"\"Initialize weights with random values in [-1, 1] (including bias)\"\"\"\n",
    "    layers, weights = len(nodes), []\n",
    "    \n",
    "    for i in range(1, layers):\n",
    "        w = [[np.random.uniform(-1, 1) for k in range(nodes[i-1] + 1)]\n",
    "              for j in range(nodes[i])]\n",
    "        weights.append(np.matrix(w))\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ForwardPropagation(x, weights, layers):\n",
    "    activations, layer_input = [x], x\n",
    "    for j in range(layers):\n",
    "        activation = Sigmoid(np.dot(layer_input, weights[j].T))\n",
    "        activations.append(activation)\n",
    "        layer_input = np.append(1, activation) # Augment with bias\n",
    "    \n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BackPropagation(y, activations, weights, layers):\n",
    "    outputFinal = activations[-1]\n",
    "    error = np.matrix(y - outputFinal) # Error at output\n",
    "    \n",
    "    for j in range(layers, 0, -1):\n",
    "        currActivation = activations[j]\n",
    "        \n",
    "        if(j > 1):\n",
    "            # Augment previous activation\n",
    "            prevActivation = np.append(1, activations[j-1])\n",
    "        else:\n",
    "            # First hidden layer, prevActivation is input (without bias)\n",
    "            prevActivation = activations[0]\n",
    "        \n",
    "        delta = np.multiply(error, SigmoidDerivative(currActivation))\n",
    "        weights[j-1] += lr * np.multiply(delta.T, prevActivation)\n",
    "\n",
    "        w = np.delete(weights[j-1], [0], axis=1)         \n",
    "        error = np.dot(delta, w) # Calculate error for current layer\n",
    "    \n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(X, Y, lr, weights):\n",
    "    layers = len(weights)\n",
    "    for i in range(len(X)):\n",
    "        x, y = X[i], Y[i]\n",
    "        x = np.matrix(np.append(1, x)) # Augment feature vector\n",
    "        \n",
    "        activations = ForwardPropagation(x, weights, layers)\n",
    "        weights = BackPropagation(y, activations, weights, layers)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def SigmoidDerivative(x):\n",
    "    return np.multiply(x, 1-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(item, weights):\n",
    "    layers = len(weights)\n",
    "    item = np.append(1, item) # Augment feature vector\n",
    "    \n",
    "    ##_Forward Propagation_##\n",
    "    activations = ForwardPropagation(item, weights, layers)\n",
    "    \n",
    "    outputFinal = activations[-1].A1\n",
    "    index = FindMaxActivation(outputFinal)\n",
    "\n",
    "    # Initialize prediction vector to zeros\n",
    "    y = [0 for i in range(len(outputFinal))]\n",
    "    y[index] = 1  # Set guessed class to 1\n",
    "\n",
    "    return y # Return prediction vector\n",
    "\n",
    "\n",
    "def FindMaxActivation(output):\n",
    "    \"\"\"Find max activation in output\"\"\"\n",
    "    m, index = output[0], 0\n",
    "    for i in range(1, len(output)):\n",
    "        if(output[i] > m):\n",
    "            m, index = output[i], i\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(X, Y, weights):\n",
    "    \"\"\"Run set through network, find overall accuracy\"\"\"\n",
    "    correct = 0\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        x, y = X[i], list(Y[i])\n",
    "        guess = Predict(x, weights)\n",
    "\n",
    "        if(y == guess):\n",
    "            # Guessed correctly\n",
    "            correct += 1\n",
    "\n",
    "    return correct / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20\n",
      "Training Accuracy:0.868421052631579\n",
      "Validation Accuracy:0.7692307692307693\n",
      "Epoch 40\n",
      "Training Accuracy:0.9736842105263158\n",
      "Validation Accuracy:1.0\n",
      "Epoch 60\n",
      "Training Accuracy:0.9736842105263158\n",
      "Validation Accuracy:1.0\n",
      "Epoch 80\n",
      "Training Accuracy:0.9649122807017544\n",
      "Validation Accuracy:1.0\n",
      "Epoch 100\n",
      "Training Accuracy:0.9736842105263158\n",
      "Validation Accuracy:1.0\n"
     ]
    }
   ],
   "source": [
    "f = len(X[0]) # Number of features\n",
    "o = len(Y[0]) # Number of outputs / classes\n",
    "\n",
    "layers = [f, 5, 10, o] # Number of nodes in layers\n",
    "lr, epochs = 0.15, 100\n",
    "\n",
    "weights = NeuralNetwork(X_train, Y_train, X_val, Y_val, epochs=epochs, nodes=layers, lr=lr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.9565217391304348\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy: {}\".format(Accuracy(X_test, Y_test, weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "for i in range(len(X_test)):\n",
    "    x= X_test[i]\n",
    "    guess = Predict(x, weights)\n",
    "    y_pred.append(guess)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(ls):\n",
    "    if ls[0]==1:\n",
    "        return \"s\"\n",
    "    elif ls[1]==1:\n",
    "        return \"versi\"\n",
    "    else :\n",
    "        return \"virginca\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_pred=[]\n",
    "y_test_final=[]\n",
    "for i in range(len(X_test)):\n",
    "    y_final_pred.append(fun(y_pred[i]))\n",
    "    y_test_final.append(fun(Y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 0, 0],\n",
       "       [0, 7, 1],\n",
       "       [0, 0, 6]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_final,y_final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9 0 0]\n",
      " [0 7 1]\n",
      " [0 0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           s      1.000     1.000     1.000         9\n",
      "       versi      1.000     0.875     0.933         8\n",
      "    virginca      0.857     1.000     0.923         6\n",
      "\n",
      "    accuracy                          0.957        23\n",
      "   macro avg      0.952     0.958     0.952        23\n",
      "weighted avg      0.963     0.957     0.957        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Print the confusion matrix\n",
    "s=\"Setosa\"\n",
    "versi=\"Versicolor\"\n",
    "virginca=\"Viginica\"\n",
    "print(metrics.confusion_matrix(y_test_final,y_final_pred))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_test_final,y_final_pred, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
